{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1JH-eXa8iWNL",
   "metadata": {
    "id": "1JH-eXa8iWNL"
   },
   "source": [
    "Пытаемся реализовать парсинг сайта cian.ru. Нами был выбран город *Махачкала*, собираем информацию только про те квартиры, которые сдаются посуточно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894699ad",
   "metadata": {
    "id": "894699ad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # библиотека для анализа HTML-кода WEB-страниц\n",
    "from selenium import webdriver # библиотека для работы с веб драйверами( уменьшения проблем свзанных с множественными переходами на сайты) (с ней происходит меньше проблем при наличии защиты от ддос атак)\n",
    "\n",
    "\n",
    "\n",
    "def parsCian(page):\n",
    "    '''Функция сбора ссылок всех квартир с каждой страницы сайта'''\n",
    "    currPage = \"https://mahachkala.cian.ru/cat.php?deal_type=rent&engine_version=2&offer_type=flat&p=\" + str(page)  +\"&region=4857&type=1\"\n",
    "    driver = webdriver.Chrome() #запускаем пакет селениума и драйвер браузера\n",
    "    driver.get(currPage) #переходим на страницу\n",
    "    data = driver.page_source #получаем код страницы\n",
    "    soup = BeautifulSoup(data, \"html.parser\") #передаем страничку - выйдет html-код странички\n",
    "    links = []\n",
    "    \n",
    "    for i in soup.find_all(\"a\", {\"class\": \"_93444fe79c--link--eoxce\"}): #извлекаем все URL-адреса, найденные на странице в тегах <a>\n",
    "        if i:\n",
    "            links.append(i.get(\"href\")) #возвращаем и сохраняем в links значение ссылки\n",
    "\n",
    "    return links\n",
    "\n",
    "allLinks = []\n",
    "for i in range(1,60,1): #парсим 60 страниц, выбран такой интервал, чтобы в итоге получилось большее 1000 наблюдений\n",
    "    allLinks += parsCian(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HrpeL0DFOT7L",
   "metadata": {
    "id": "HrpeL0DFOT7L"
   },
   "source": [
    "Собираем все странички квартир. Удаляем те, которые сильно отличаются от остальных (мало информации или сильно отличающаяся информация от большинства страниц)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558e9bf0",
   "metadata": {
    "id": "558e9bf0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "#удаляем ссылки которые не подходят из-за сильных различий в структуре html и некоторых другие метки \n",
    "allLinksFiltered = [el for el, _ in groupby(allLinks)]\n",
    "allLinksFiltered2 = []\n",
    "for i in allLinksFiltered:\n",
    "    if(\"cian.tvil.ru\" not in i):\n",
    "        allLinksFiltered2.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WYpgU0xtNwfa",
   "metadata": {
    "id": "WYpgU0xtNwfa"
   },
   "source": [
    "В функции собираем интересующие нас метки со страничек каждой квартиры.\n",
    "Выбраны метки, чаще всего встречающиеся на страничках, которые, по нашему мнению, наиболее важны для заселяющихся и с которыми дальше можно будет что-то придумать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7765be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent #будем имитировать реального пользователя с помощью этого пакета\n",
    "from selenium.webdriver.chrome.options import Options #добавляем опции хрома\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374ee94",
   "metadata": {
    "id": "b374ee94",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Тапок\\AppData\\Local\\Temp\\ipykernel_1812\\4240956828.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options) #использование выбранных выше опций при парсинге\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def parsLink(link):\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument('--headless'); # отключение открытия на компьютере нового браузера для каждой страницы\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random  #генерация случайного \"пользователя\" для каждой страницы(для обхода защиты)\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "    driver = webdriver.Chrome(chrome_options=options) #использование выбранных выше опций при парсинге\n",
    "    driver.get(str(link))\n",
    "    data = driver.page_source\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    \n",
    "    #Получаем цену\n",
    "    try:\n",
    "        price = soup.find_all('span', {'itemprop' : 'price'}) #достаем данные о цене\n",
    "        priceValue = price[0].text\n",
    "        priceArr = priceValue.split(\"\\xa0\") #разделяем цену от валюты (\"\\xa0\" неразрывный пробел)\n",
    "        price = priceArr[1] + priceArr[2] # соединяем тысячи и остальные цифры\n",
    "    except:\n",
    "        price = 0\n",
    "    \n",
    "    #получаем агенство\n",
    "    try:\n",
    "        agency = soup.find_all('div', {'class' : 'a10a3f92e9--title--YaRYv'})[0].text \n",
    "        \n",
    "    except:\n",
    "        agency = 0\n",
    "        \n",
    "    #общая площадь\n",
    "    try:\n",
    "        total = soup.find_all('div', {'class' : 'a10a3f92e9--info-value--bm3DC'})[0].text.split(\"\\xa0\")[0] #общая площадь и жилая имели одинаковые теги, поэтому получаем массив элементов, 1-й элемент массива общая, 2-й жилая\n",
    "        if(\"из\" in total):\n",
    "            total = 0\n",
    "        \n",
    "    except:\n",
    "        total = 0\n",
    "    \n",
    "    #жилая\n",
    "    try:\n",
    "        living = soup.find_all('div', {'class' : 'a10a3f92e9--info-value--bm3DC'})[1].text.split(\"\\xa0\")[0]\n",
    "        if(\"из\" in living):\n",
    "            living = 0\n",
    "        \n",
    "    except:\n",
    "        living = 0\n",
    "    \n",
    "    #этаж\n",
    "    try:\n",
    "        floor = 0\n",
    "        floorText = soup.find_all('div', {'class' : 'a10a3f92e9--info-value--bm3DC'})\n",
    "        for i in floorText:\n",
    "            if(\"из\" in i.text):\n",
    "                floor = i.text.split(\" \")[0]#этаж содержался в формате 4 из 10, поэтому достаем 1-ю цифру из записи для текущего этажа\n",
    "        \n",
    "    except:\n",
    "        floorText = 0\n",
    "        floor = 0\n",
    "    \n",
    "    #всего этажей\n",
    "    \n",
    "    try:\n",
    "        totalFloor = 0\n",
    "        floorText = soup.find_all('div', {'class' : 'a10a3f92e9--info-value--bm3DC'})\n",
    "        for i in floorText:\n",
    "            if(\"из\" in i.text):\n",
    "                totalFloor = i.text.split(\" \")[2] #так же как и в прошлом пункте, но берем последнюю\n",
    "    except:\n",
    "        totalFloor = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Дети\n",
    "    kids = 0\n",
    "    try:\n",
    "        kids = soup.find_all('li', {'class' : 'a10a3f92e9--item--DCJ3N a10a3f92e9--kids--hABK5'})\n",
    "        if(kids[0].text == \"Можно с детьми\"):\n",
    "            kids = 1\n",
    "    except:\n",
    "        kids = 0\n",
    "    \n",
    "    #фурнитура\n",
    "    \n",
    "    try:\n",
    "        features = soup.find_all('ul', {'class' : 'a10a3f92e9--container--P4zGu'})[-1].text #получаем список фурнитуры и проверям наличие по вхождению\n",
    "        fridge = 0 \n",
    "        dishwasher = 0\n",
    "        washmashine = 0\n",
    "        roomfurniture = 0\n",
    "        kitchenfurniture = 0\n",
    "        TV = 0\n",
    "        net = 0\n",
    "        condition = 0\n",
    "        dush = 0\n",
    "        vanna = 0\n",
    "        if 'Холодильник' in features:\n",
    "            fridge = 1\n",
    "        if 'Посудомоечная машина' in features:\n",
    "            dishwasher = 1\n",
    "        if 'Стиральная машина' in features:\n",
    "            washmashine = 1\n",
    "        if 'Мебель в комнатах' in features:\n",
    "            roomfurniture = 1\n",
    "        if 'Мебель на кухне' in features:\n",
    "            kitchenfurniture = 1\n",
    "        if 'Телевизор' in features:\n",
    "            TV = 1\n",
    "        if 'Интернет' in features:\n",
    "            net = 1\n",
    "        if 'Кондиционер' in features:\n",
    "            condition = 1\n",
    "        if 'Душевая кабина' in features:\n",
    "            dush = 1\n",
    "        if 'Ванна' in features:\n",
    "            vanna = 1\n",
    "    except:\n",
    "        fridge = 0 \n",
    "        dishwasher = 0\n",
    "        washmashine = 0\n",
    "        roomfurniture = 0\n",
    "        kitchenfurniture = 0\n",
    "        TV = 0\n",
    "        net = 0\n",
    "        condition = 0\n",
    "        dush = 0\n",
    "        vanna = 0\n",
    "    \n",
    "    \n",
    "    #aдрес\n",
    "    district = 0\n",
    "    street = 0\n",
    "    fulladdress = 0\n",
    "    try:\n",
    "        fulladdress = soup.find_all('a', {'class' : 'a10a3f92e9--link--ulbh5 a10a3f92e9--address-item--ScpSN'})#получаем список данных о адресе(имеют только общие теги)\n",
    "        for i in fulladdress:\n",
    "            if(\"р-н\" in i.text or \"район\" in i.text): #проверяем не является ли районом элемент\n",
    "                district = i.text.replace(\"р-н\", \"\").replace(\"район\",\"\") #меняем сокращения слова район на слово район для однородности\n",
    "            if(\"ул\" in i.text or \"туп\" in i.text):#проверяем не является ли улицей элемент\n",
    "                street = i.text.replace(\"ул.\", \"\").replace(\"улица\", \"\").replace(\"туп.\", \"\")#делаем как с районом\n",
    "    except:\n",
    "        fulladdress = 0\n",
    "        resp = 0\n",
    "        district = 0\n",
    "        street = 0\n",
    "        house = 0\n",
    "    \n",
    "    \n",
    "    ans = [link, price, agency, total, living, floor, totalFloor, kids, fridge,\n",
    "          dishwasher, washmashine, roomfurniture, kitchenfurniture, TV, net, \n",
    "          condition, dush, vanna, district, street] #собираем все вместе\n",
    "    return ans #возвращаем данные о квартире\n",
    "# В data собираем данные с каждой ссылочки через прогон функции parsLink\n",
    "data = []\n",
    "for i in allLinksFiltered2:\n",
    "    data.append(parsLink(i)) #собираем данные вместе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oHQz4zGRPkL_",
   "metadata": {
    "id": "oHQz4zGRPkL_"
   },
   "source": [
    "Итоговый датафрейм, который дальше будет редачиться и юзаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f4892",
   "metadata": {
    "id": "3f3f4892",
    "outputId": "51983cea-1681-4766-d1c3-fa723872b7c8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df =pd.DataFrame(data = data, columns =  [\"ссылка\", \"цена\", \"агенство\", \"общая площадь\", \"жилая площадь\", \"этаж\",\n",
    "             \"всего этажей\", \"Дети\", \"холодильник\", \"посудомойка\", \"стиральная машина\",\n",
    "             \"мебель в комнатах\", \"мебель на кухне\", \"телевизор\", \"интернет\", \"кондиционер\",\n",
    "             \"душ\", \"ванна\", \"район\", \"улица\"]) #задаем параметры для таблицы и заполняем ее данными\n",
    "\n",
    "\n",
    "df.style.hide_index()\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z8IC5mUKPpRJ",
   "metadata": {
    "id": "z8IC5mUKPpRJ"
   },
   "source": [
    "Записываем в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee56c7",
   "metadata": {
    "id": "abee56c7"
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\murad\\OneDrive\\Рабочий стол\\dataframe.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RhEeAzJ8Pwq3",
   "metadata": {
    "id": "RhEeAzJ8Pwq3"
   },
   "outputs": [],
   "source": [
    "#удалили после чекпоинта все технические принты и пипы, оставили только вывод датафрейма"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
